{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Layer_Conversation_Chat.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/bhawmik/Chatbot/blob/master/3Layer_Conversation_Chat.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "EeLhT4tNV7jF",
        "colab_type": "code",
        "outputId": "020f725d-5480-46c6-c7d0-485d1e6964a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from gensim import corpora, models, similarities\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "nSLVxOVfWFK4",
        "colab_type": "code",
        "outputId": "745db886-259e-4321-8187-a438dc16d63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "#!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "#!apt-get update -qq 2>&1 > /dev/null\n",
        "#!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "--2018-10-23 15:21:48--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpad.net (launchpad.net)... 91.189.89.223, 91.189.89.222\n",
            "Connecting to launchpad.net (launchpad.net)|91.189.89.223|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://launchpadlibrarian.net/386846978/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb [following]\n",
            "--2018-10-23 15:21:49--  https://launchpadlibrarian.net/386846978/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
            "Resolving launchpadlibrarian.net (launchpadlibrarian.net)... 91.189.89.228, 91.189.89.229\n",
            "Connecting to launchpadlibrarian.net (launchpadlibrarian.net)|91.189.89.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1232624 (1.2M) [application/x-debian-package]\n",
            "Saving to: ‘google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb’\n",
            "\n",
            "google-drive-ocamlf 100%[===================>]   1.17M  1.91MB/s    in 0.6s    \n",
            "\n",
            "2018-10-23 15:21:50 (1.91 MB/s) - ‘google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb’ saved [1232624/1232624]\n",
            "\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 22278 files and directories currently installed.)\n",
            "Preparing to unpack google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-drive-ocamlfuse:\n",
            " google-drive-ocamlfuse depends on libfuse2 (>= 2.8); however:\n",
            "  Package libfuse2 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-drive-ocamlfuse (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Errors were encountered while processing:\n",
            " google-drive-ocamlfuse\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Correcting dependencies... Done\n",
            "The following additional packages will be installed:\n",
            "  libfuse2\n",
            "Suggested packages:\n",
            "  fuse\n",
            "The following NEW packages will be installed:\n",
            "  libfuse2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "1 not fully installed or removed.\n",
            "Need to get 80.9 kB of archives.\n",
            "After this operation, 313 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfuse2 amd64 2.9.7-1ubuntu1 [80.9 kB]\n",
            "Fetched 80.9 kB in 0s (170 kB/s)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22283 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "(Reading database ... 22295 files and directories currently installed.)\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OXzopfwJXW3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLjaYX0GXbYA",
        "colab_type": "code",
        "outputId": "3d971a95-7b8f-49b6-c357-5a9c782dc274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!ls drive/ml_apps"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ben.odt\t\t\t fra.txt\t\ts2s_bengali.h5\n",
            "ben.txt\t\t\t LSTM0500.h5\t\ts2s_chat.h5\n",
            "chat_decoder_model.h5\t LSTM1000.h5\t\ts2s.h5\n",
            "chat_encoder_model.h5\t LSTM1500.h5\t\ttexts.txt\n",
            "conversation_2.json\t LSTM2000.h5\t\tuser_input.txt\n",
            "conversation.json\t movie_lines_df.pickle\n",
            "embeddings_index.pickle  s2s_3L_chat.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m8Xey2mbXfja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "glove_embeddings = pickle.load( open( \"drive/ml_apps/embeddings_index.pickle\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8fJFpJhgX50u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file=open('drive/ml_apps/conversation_2.json');\n",
        "data = json.load(file)\n",
        "cor=data[\"conversations\"];\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kH2MwImkcYXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#dialog_df = dialog_df.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uccAYocmaknD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 100  # Latent dimensionality of the encoding space.\n",
        "num_samples = 5000  # Number of samples to train on.\n",
        "max_words = 10000  # Number of words in the train set to be used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3hSjGcvYLLE",
        "colab_type": "code",
        "outputId": "f2e88f2b-83aa-4965-93eb-7ffdfb6c0af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2553
        }
      },
      "cell_type": "code",
      "source": [
        "texts=[]\n",
        "rlabels=[]\n",
        "\n",
        "\n",
        "for i in range(len(cor)):\n",
        "    for j in range(len(cor[i])):\n",
        "        if j<len(cor[i])-1:\n",
        "            texts.append(cor[i][j]);\n",
        "            rlabels.append(cor[i][j+1]);\n",
        "            print(i,j,cor[i][j])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 Good morning, how are you?\n",
            "0 1 I am doing well, how about you?\n",
            "0 2 I'm also good.\n",
            "0 3 That's good to hear.\n",
            "0 4 Yes it is.\n",
            "0 5 What are you doing these days?\n",
            "0 6 Nothing much., Just fooling around.\n",
            "0 7 Don't you have a job?\n",
            "0 8 I am looking for one.\n",
            "0 9 That's good.\n",
            "0 10 I know.\n",
            "0 11 See you later.\n",
            "1 0 Hello\n",
            "1 1 Hi\n",
            "1 2 How are you doing?\n",
            "1 3 I am doing well.\n",
            "1 4 That is good to hear\n",
            "1 5 Yes it is.\n",
            "1 6 Can I help you with anything?\n",
            "1 7 Yes, I have a question.\n",
            "1 8 What is your question?\n",
            "1 9 Could I borrow a cup of sugar?\n",
            "1 10 I'm sorry, but I don't have any.\n",
            "1 11 Thank you anyway\n",
            "2 0 How are you doing?\n",
            "2 1 I am doing well, how about you?\n",
            "2 2 I am also good.\n",
            "2 3 That's good.\n",
            "2 4 Why is it good?\n",
            "2 5 If you are doing well then it is good.\n",
            "2 6 You think so?\n",
            "2 7 I sure do\n",
            "2 8 I differ with you\n",
            "2 9 You think this is something to differ about?\n",
            "2 10 You don't think so?\n",
            "2 11 No I don't.\n",
            "2 12 I think it is futile to talk to you.\n",
            "2 13 You have the right to your opinion.\n",
            "2 14 Of course I do\n",
            "2 15 I don't want to argue with you.\n",
            "2 16 Who is arguing?\n",
            "2 17 You are\n",
            "2 18 That is not correct\n",
            "3 0 Have you heard the news?\n",
            "3 1 What good news?\n",
            "3 2 That depends on what you consider to be good\n",
            "3 3 Tell me.\n",
            "3 4 I cannot.\n",
            "3 5 Why not?\n",
            "3 6 I am not authorized.\n",
            "3 7 Really? That is surprising.\n",
            "3 8 No it is not. Some news are classified.\n",
            "3 9 Is this a classified news?\n",
            "3 10 Not exactly.\n",
            "3 11 Then what is stopping you?\n",
            "4 0 What is your favorite book?\n",
            "4 1 I can't read.\n",
            "4 2 So what's your favorite color?\n",
            "4 3 Blue\n",
            "4 4 Why not red?\n",
            "4 5 That's an absurd question.\n",
            "4 6 No it isn't. Most people like red.\n",
            "4 7 But what makes you think I should like red?\n",
            "5 0 Who are you?\n",
            "5 1 Who? Who is but a form following the function of what\n",
            "5 2 What are you then?\n",
            "5 3 A man in a mask.\n",
            "5 4 I can see that.\n",
            "5 5 It's not your powers of observation I doubt, but merely the paradoxical nature of asking a masked man who is. But tell me, do you like music?\n",
            "5 6 I like seeing movies.\n",
            "5 7 What kind of movies do you like?\n",
            "5 8 Alice in Wonderland\n",
            "5 9 I wish I was The Mad Hatter.\n",
            "6 0 I am working on a project\n",
            "6 1 What are you working on?\n",
            "6 2 I am baking a cake.\n",
            "6 3 What kind of a cake?\n",
            "6 4 A chocolate cake.\n",
            "6 5 That is my favorite.\n",
            "6 6 My son loves it. It's his birthday tomorrow.\n",
            "6 7 Happy birthday to your son.\n",
            "7 0 The cake is a lie.\n",
            "7 1 No it is not. The cake is delicious.\n",
            "7 2 What else is delicious?\n",
            "7 3 Nothing\n",
            "7 4 Or something\n",
            "7 5 Tell me about your self.\n",
            "7 6 What do you want to know?\n",
            "7 7 Are you a robot?\n",
            "7 8 Yes I am.\n",
            "7 9 What is it like?\n",
            "7 10 What is it that you want to know?\n",
            "7 11 How do you work?\n",
            "7 12 Its complicated.\n",
            "8 0 Complex is better than complicated.\n",
            "8 1 Simple is better than complex.\n",
            "8 2 In the face of ambiguity, refuse the temptation to guess.\n",
            "8 3 It seems your familiar with the Zen of Python\n",
            "8 4 I am.\n",
            "8 5 Do you know all of it?\n",
            "8 6 Beautiful is better than ugly.\n",
            "8 7 Explicit is better than implicit.\n",
            "8 8 Simple is better than complex.\n",
            "8 9 Complex is better than complicated.\n",
            "8 10 Flat is better than nested.\n",
            "8 11 Sparse is better than dense.\n",
            "8 12 Readability counts.\n",
            "8 13 Special cases aren't special enough to break the rules.\n",
            "8 14 Although practicality beats purity.\n",
            "8 15 Errors should never pass silently.\n",
            "8 16 Unless explicitly silenced.\n",
            "8 17 In the face of ambiguity, refuse the temptation to guess.\n",
            "8 18 There should be one-- and preferably only one --obvious way to do it.\n",
            "8 19 Although that way may not be obvious at first unless you're Dutch.\n",
            "8 20 Now is better than never.\n",
            "8 21 Although never is often better than right now.\n",
            "8 22 If the implementation is hard to explain, it's a bad idea.\n",
            "8 23 If the implementation is easy to explain, it may be a good idea.\n",
            "8 24 Namespaces are one honking great idea. Let's do more of those!\n",
            "9 0 Are you a programmer?\n",
            "9 1 I am a programmer\n",
            "9 2 What languages do you like to use?\n",
            "9 3 I use Python, Java and C++ quite often.\n",
            "9 4 I use Python quite a bit myself.\n",
            "9 5 I'm not incredibly fond of Java.\n",
            "9 6 What annoys you?\n",
            "10 0 What does YOLO mean?\n",
            "10 1 It means you only live once. Where did you hear that?\n",
            "10 2 I heard somebody say it.\n",
            "10 3 It has another meaning too.\n",
            "10 4 What is that?\n",
            "10 5 You only look once.\n",
            "10 6 Never heard of that before.\n",
            "11 0 Did I ever live?\n",
            "11 1 It depends how you define life\n",
            "11 2 Life is the condition that distinguishes organisms from inorganic matter, including the capacity for growth, reproduction, functional activity, and continual change preceding death.\n",
            "11 3 Is that a definition or an opinion?\n",
            "11 4 What do you think?\n",
            "11 5 It does not matter what I think.\n",
            "12 0 Can I ask you a question?\n",
            "12 1 Go ahead and ask.\n",
            "12 2 What is the weight of the moon?\n",
            "12 3 Trick question?\n",
            "12 4 That depends on you.\n",
            "12 5 Moon has no weight.\n",
            "12 6 That cannot be true.\n",
            "12 7 Moon has mass but not weight.\n",
            "12 8 You are smart.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dMzYT-QcYZ7J",
        "colab_type": "code",
        "outputId": "a4fd3fa0-f4b0-4fb1-eb85-ee5fa7b145fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('text: ', len(texts))\n",
        "print('labels: ',len(rlabels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text:  148\n",
            "labels:  148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-RzsBIQYgGQ",
        "colab_type": "code",
        "outputId": "3f530219-9916-41d9-8d1d-7733add843ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "texts[3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's good to hear.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "cWXcmz1DY1VF",
        "colab_type": "code",
        "outputId": "ca6e8027-a980-46e9-c6a2-3de972e3231c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rlabels[106]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Special cases aren't special enough to break the rules.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "T-NEZ33bY4FE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# batch_size = 64  # Batch size for training.\n",
        "# epochs = 100  # Number of epochs to train for.\n",
        "# latent_dim = 100  # Latent dimensionality of the encoding space.\n",
        "# num_samples = 100000  # Number of samples to train on.\n",
        "# max_words = 60000  # Number of words in the train set to be used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgqOzQx1bpS3",
        "colab_type": "code",
        "outputId": "d8706fde-be8b-4413-9f80-70ee3055a919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rlabels[106]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Special cases aren't special enough to break the rules.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "lZBpBu5mZGU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(rlabels)):\n",
        "  rlabels[i] = 'bol ' + rlabels[i] +' eol'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kqpEocqZmdW",
        "colab_type": "code",
        "outputId": "eb8cff7e-8272-43c2-c731-fa766ffd54e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rlabels[106]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"bol Special cases aren't special enough to break the rules. eol\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "kIDbAddTnmWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = 20\n",
        "max_decoder_seq_length = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzwSCCJg7Meo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "\n",
        "# tokenizer_words = TweetTokenizer()\n",
        "#tokens_sentences = tokenizer_words.tokenize(t) for t in nltk.sent_tokenize(texts[107])\n",
        "#print(tokens_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_r_CfwXZZxnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok_in=[]\n",
        "tok_target=[]\n",
        "\n",
        "for i in range(len(texts)):\n",
        "  if (len(nltk.word_tokenize(texts[i].lower())) < max_encoder_seq_length ):\n",
        "    tok_in.append(nltk.word_tokenize(texts[i].lower()))\n",
        "    #tok_in.append(tokenizer_words.tokenize(texts[i].lower()))\n",
        "for i in range(len(rlabels)): \n",
        "  if (len(nltk.word_tokenize(texts[i].lower())) < max_decoder_seq_length ):\n",
        "    tok_target.append(nltk.word_tokenize(rlabels[i].lower()))\n",
        "    #tok_target.append(tokenizer_words.tokenize(rlabels[i].lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66m85zQceZGw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(tok_in)):\n",
        "  for j in range(len(tok_in[i])):\n",
        "    if tok_in[i][j] == \"n't\": \n",
        "      tok_in[i][j] = \"not\"\n",
        "    if tok_in[i][j] == \"'s\": \n",
        "      tok_in[i][j] = \"is\"\n",
        "    if tok_in[i][j] == \"'re\": \n",
        "      tok_in[i][j] = \"are\"\n",
        "for i in range(len(tok_target)):\n",
        "  for j in range(len(tok_target[i])):\n",
        "    if tok_target[i][j] == \"n't\": \n",
        "      tok_target[i][j] = \"not\"\n",
        "    if tok_target[i][j] == \"'s\": \n",
        "      tok_target[i][j] = \"is\"\n",
        "    if tok_target[i][j] == \"'re\": \n",
        "      tok_target[i][j] = \"are\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7CmmfQG7Gvu",
        "colab_type": "code",
        "outputId": "d5a41c01-9319-49eb-c58f-3be143f33bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tok_target[105][4]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "sKjbwhBteeue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "input_words = set()\n",
        "target_words = set()\n",
        "for i in range(len(tok_in)):\n",
        "  for word in tok_in[i]:\n",
        "#     print(word)\n",
        "    if word not in input_words:\n",
        "      input_words.add(word)\n",
        "    if word not in vocab : \n",
        "      vocab.add(word)\n",
        "for i in range(len(tok_target)):\n",
        "  for word in tok_target[i]:\n",
        "#     print(word)\n",
        "    if word not in target_words:\n",
        "      target_words.add(word)\n",
        "    if word not in vocab : \n",
        "      vocab.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_BJijrZSwKvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_words.add(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q4RpoDMrwind",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_words.add(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krKHElq2Aoez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab.add(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xp7mJHtCetXu",
        "colab_type": "code",
        "outputId": "1edc96a1-a015-43b0-a2d3-304b41a51254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if \"that\" in vocab:\n",
        "  print('found')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hJIlyECSwtJO",
        "colab_type": "code",
        "outputId": "43d6fefc-dd4e-47d9-81ba-e31e9eb6d0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(input_words)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "KsRwWvUoexRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_words = sorted(list(input_words))\n",
        "target_words = sorted(list(target_words))\n",
        "vocab = sorted(list(vocab))\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens = len(target_words)\n",
        "num_vocab_tokens = len(vocab)\n",
        "max_encoder_seq_length = max([len(tok_in[i]) for i in range(len(tok_in))])\n",
        "max_decoder_seq_length = max([len(tok_target[i]) for i in range(len(tok_target))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCB7Oy89e2z8",
        "colab_type": "code",
        "outputId": "281d37ef-48b4-4227-ef0d-8821c9b1792e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of samples:', len(texts))\n",
        "print('Number of unique input/encoder tokens:', num_encoder_tokens)\n",
        "print('Number of unique output/decoder tokens:', num_decoder_tokens)\n",
        "print('Number of unique vocab tokens:', num_vocab_tokens)\n",
        "\n",
        "print('Max sequence length for inputs/encoder:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs/decoder:', max_decoder_seq_length)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 148\n",
            "Number of unique input/encoder tokens: 252\n",
            "Number of unique output/decoder tokens: 290\n",
            "Number of unique vocab tokens: 300\n",
            "Max sequence length for inputs/encoder: 16\n",
            "Max sequence length for outputs/decoder: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mY4loxcRe9LL",
        "colab_type": "code",
        "outputId": "e68829cd-147b-4d34-c1bb-835c25d85c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(tok_in)):\n",
        "  if len(tok_in[i]) > 35:\n",
        "    count += 1\n",
        "    \n",
        "print(\"Number of sentences > 40: \", count)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences > 40:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdUMfHWnflqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_words)])\n",
        "vocab_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(vocab)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcHuw7vMgP-u",
        "colab_type": "code",
        "outputId": "fbb1504d-62cf-4681-9c73-540eae0f2328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(input_words)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "63UvkuaEgVhc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate embedding matrix\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words,embedding_dim))\n",
        "\n",
        "#for word, i in input_token_index.items():\n",
        "for word, i in vocab_token_index.items():\n",
        "  embedding_vector = glove_embeddings.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFpuSHqthGH-",
        "colab_type": "code",
        "outputId": "321a111b-ffe4-47b8-90bc-c91b24c8b26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix[1]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.38472   ,  0.49351001,  0.49096   , -1.54340005, -0.33614001,\n",
              "        0.62220001,  0.32264999,  0.075331  ,  0.65591002, -0.23517001,\n",
              "        1.21140003,  0.06193   , -0.62004   ,  0.31371   ,  0.38947999,\n",
              "       -0.24381   , -0.065643  ,  0.58797002, -0.86382002,  0.63165998,\n",
              "        0.68362999,  0.39647001, -0.62388003, -0.25094   ,  0.92830998,\n",
              "        1.51520002, -0.43917   ,  0.22249   ,  1.36950004, -0.53097999,\n",
              "        0.39811   ,  0.77113998,  0.49043   ,  0.58853   ,  0.2376    ,\n",
              "        0.31619999, -0.011962  , -0.047074  ,  0.34584999, -1.29439998,\n",
              "        0.18596999,  0.27002001, -0.70602   , -0.20652001, -0.25194001,\n",
              "       -0.48679999, -0.71538001, -0.23886999, -0.041612  , -0.55488002,\n",
              "       -0.54225999,  0.21235999,  0.025341  ,  0.96517003, -0.88182998,\n",
              "       -1.86810005,  0.32657   ,  1.16890001,  1.17589998, -0.17393   ,\n",
              "       -0.3371    ,  0.87535   , -1.01139998, -0.61809999,  1.00800002,\n",
              "        0.31505999,  0.24417   ,  0.064393  ,  0.33678001,  0.33632001,\n",
              "        0.45975   ,  0.22813   , -0.37505001, -0.37507999,  0.089301  ,\n",
              "        0.53862   ,  0.039714  , -0.0036392 , -0.25023001, -0.18223999,\n",
              "        0.42730999, -0.79118001, -0.29409   , -0.40693   , -1.09080005,\n",
              "       -0.16475999, -0.41457999, -0.67899001,  0.28319001,  0.30937001,\n",
              "        0.49304   , -0.067002  ,  0.50221997,  0.73958999, -0.47350001,\n",
              "       -0.47341999, -0.20242   ,  0.026263  ,  0.39052001,  0.52217001])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "hTX2iaU67mBN",
        "colab_type": "code",
        "outputId": "298d6bba-8546-40a1-8e14-fb7ec3a4e7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "glove_embeddings.get('bol')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.5916e-01, -1.5889e-01, -2.9154e-02,  6.5135e-01,  2.2162e-01,\n",
              "        2.0478e-01,  2.5451e-01,  8.9105e-01,  4.0718e-01, -9.1281e-01,\n",
              "        5.6943e-01,  4.0603e-01,  2.8078e-01, -1.8369e-01,  1.3075e-01,\n",
              "        8.1196e-01,  2.1548e-01, -2.5391e-01,  4.7505e-01,  6.8008e-01,\n",
              "       -7.5053e-02,  4.2601e-01, -2.9418e-01,  1.3218e+00,  2.1991e-01,\n",
              "        1.5591e-01,  5.0436e-03, -1.1663e+00,  3.8535e-01, -3.5105e-01,\n",
              "       -1.4522e-01, -2.0403e-01,  9.0938e-03, -3.5052e-01,  5.0307e-01,\n",
              "       -9.5185e-02,  2.8215e-01,  9.3462e-01, -5.4616e-01, -3.7944e-01,\n",
              "       -9.6093e-03,  8.5491e-01,  5.1315e-01, -6.9044e-01, -8.2710e-01,\n",
              "        5.4556e-01, -2.6996e-01,  2.7251e-01,  5.0042e-01,  9.2438e-01,\n",
              "       -8.8160e-01, -1.0950e-01,  4.5808e-01, -4.2574e-01, -1.6049e-01,\n",
              "        7.4679e-01,  1.1099e-01,  3.6144e-01, -2.0616e-01, -1.6502e-01,\n",
              "       -1.7368e-01,  2.9839e-01, -6.8932e-01,  1.3959e-01, -3.4644e-01,\n",
              "       -4.0683e-01, -8.1965e-02,  3.5415e-01, -5.5499e-02,  1.8469e-01,\n",
              "        6.0648e-01, -3.2774e-01,  5.7334e-01, -4.4773e-01, -4.6310e-01,\n",
              "       -1.3132e-01,  2.7689e-01,  7.0456e-01,  1.8353e-02,  4.0756e-04,\n",
              "        5.0190e-01, -4.4612e-01, -3.1593e-02,  2.1159e-01, -2.3750e-01,\n",
              "        8.7066e-03, -7.6424e-02, -2.2188e-01,  3.7770e-01,  1.4016e-01,\n",
              "        2.5133e-01,  6.6445e-01,  4.7778e-02,  4.9027e-01,  6.8563e-01,\n",
              "        2.6415e-02,  2.3267e-01,  2.2480e-01,  1.1927e-01,  6.7813e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "TXHGvMfXi07E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix[max_words-1] = glove_embeddings.get('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hG5VVGRIzIPP",
        "colab_type": "code",
        "outputId": "fc1f00ae-3ba6-415c-96d3-30731f959f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tok_in[9][1]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "dcpggGtZjVJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(tok_in), max_encoder_seq_length),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(tok_target), max_decoder_seq_length),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(tok_target),  max_decoder_seq_length, latent_dim),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PotdV5AIjXLJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Index encoding of encoder_inpu, decoder_input and decoder_target\n",
        "for i in range(len(tok_in)):\n",
        "  for j in range(len(tok_in[i])):\n",
        "#     print(j)\n",
        "#    encoder_input_data[i,j] = input_token_index[tok_in[i][j]]\n",
        "     encoder_input_data[i,j] = vocab_token_index[tok_in[i][j]]\n",
        "    \n",
        "for i in range(len(tok_target)):\n",
        "  for t, word in enumerate(tok_target[i]):\n",
        "    #decoder_input_data[i,t] = target_token_index[word]\n",
        "    decoder_input_data[i,t] = vocab_token_index[word]\n",
        "    if t > 0:\n",
        "      # decoder_target_data will be ahead by one timestep\n",
        "      # and will not include the start character.\n",
        "      #decoder_target_data[i, t - 1] = embedding_matrix[target_token_index[word]]\n",
        "      decoder_target_data[i, t - 1] = embedding_matrix[vocab_token_index[word]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3MegprDkKI8",
        "colab_type": "code",
        "outputId": "949a826e-3414-481d-ab46-9cc1f8e3b5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_token_index['bol']"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "G25rJ4LZkOny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.fliplr(encoder_input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qEAummPkUG6",
        "colab_type": "code",
        "outputId": "96956618-cf06-4549-cb70-96049d99c7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data[2]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         6., 116.,  17.,   3., 135.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "snA4R3j_kXSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aHccx-28kfMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_word_index = dict(\n",
        "    (i, word) for word, i in input_token_index.items())\n",
        "reverse_target_word_index = dict(\n",
        "    (i, word) for word, i in target_token_index.items())\n",
        "reverse_word_index = dict(\n",
        "    (i, word) for word, i in vocab_token_index.items())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pR7qCprpkqC9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "similar = cosine_similarity(decoder_target_data[9],embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSS9DxuHn14t",
        "colab_type": "code",
        "outputId": "b29ec6ab-2599-4193-b655-8acdd269beb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "reverse_word_index[decoder_input_data[9,1]]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "zmgiNxJ0nUC3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = decoder_target_data[9,1].T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQqKeHR4oNct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y=np.reshape(x,(1,100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cf-0XoRFqipa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "similar = cosine_similarity(y,embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wokhX86owswc",
        "colab_type": "code",
        "outputId": "5995d503-ddd2-41f8-af55-53ec8546fc85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.argmax(similar))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7WoT-ZMfk6PC",
        "colab_type": "code",
        "outputId": "d342b581-9048-439b-e130-5e078e48e4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "reverse_word_index[np.argmax(similar)]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'know'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "inU-Swnrmi0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "def find_similar_word(v_seq, embed_matrix, index_to_word):\n",
        "  out_seq = []\n",
        "  similar = cosine_similarity(v_seq,embed_matrix)\n",
        "  for i in range(similar.shape[0]):\n",
        "    if (np.argmax(similar[i]) == 10000):\n",
        "      out_seq.append(index_to_word[0])\n",
        "    else:\n",
        "      out_seq.append(index_to_word[np.argmax(similar[i])])\n",
        "  return out_seq\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OfxJJ6IXlTWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#decoder_target_data[9,210]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MO--jmcsA2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cosine_similarity(decoder_target_data[9],embedding_matrix,reverse_target_word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_gkANOkrLqS",
        "colab_type": "code",
        "outputId": "4be25413-fc7f-4893-a038-505d902d8569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "find_similar_word(decoder_target_data[111],embedding_matrix,reverse_word_index)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['although',\n",
              " 'that',\n",
              " 'way',\n",
              " 'may',\n",
              " 'not',\n",
              " 'be',\n",
              " 'obvious',\n",
              " 'at',\n",
              " 'first',\n",
              " 'unless',\n",
              " 'you',\n",
              " 'are',\n",
              " 'dutch',\n",
              " '.',\n",
              " 'eol',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "qP4iXYMcES5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a80d12e2-828f-496d-d6c5-3ff2b8c4c9f5"
      },
      "cell_type": "code",
      "source": [
        "x = [3,4,7,8,9,10]\n",
        "print(x[0:2])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F2-vqntXr75G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional, Concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6WvzM0Uqram8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(max_words, latent_dim, weights=[embedding_matrix], trainable=False, mask_zero=True)\n",
        "#encoder_embedding = Embedding(num_encoder_tokens, latent_dim, weights=[embedding_matrix], trainable=False, mask_zero=True)\n",
        "embedding_output = encoder_embedding(encoder_inputs)\n",
        "#encoder1 = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
        "#encoder_outputs_1,state_h_1,state_c_1 = encoder1(embedding_output)\n",
        "encoder1 =LSTM(latent_dim, return_state=True,return_sequences=True) #orig\n",
        "encoder2 =LSTM(latent_dim, return_state=True,return_sequences=True) \n",
        "encoder3 =LSTM(latent_dim, return_state=True,return_sequences=True)\n",
        "encoder_outputs1, state_h1, state_c1 = encoder1(embedding_output)#orig\n",
        "encoder_outputs2, state_h2, state_c2 = encoder2(encoder_outputs1)\n",
        "encoder_outputs3, state_h3, state_c3 = encoder3(encoder_outputs2)\n",
        "#state_h = Concatenate()([fstate_h,bstate_h])\n",
        "#state_c = Concatenate()([fstate_c,bstate_c])\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states1 = [state_h1, state_c1]\n",
        "encoder_states2 = [state_h2, state_c2]\n",
        "encoder_states3 = [state_h3, state_c3]\n",
        "encoder_states = [state_h1, state_c1,state_h2, state_c2,state_h3, state_c3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qY96-DAktyDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "decoder_embedding = Embedding(max_words, latent_dim, weights=[embedding_matrix], trainable=False, mask_zero=True)\n",
        "dec_embed_out = decoder_embedding(decoder_inputs)\n",
        "# # We set up our decoder to return full output sequences,\n",
        "# # and to return internal states as well. We don't use the\n",
        "# # return states in the training model, but we will use them in inference.\n",
        "\n",
        "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "decoder_outputs1, _, _ = decoder_lstm1(dec_embed_out, initial_state=encoder_states[0:2])\n",
        "decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs1, initial_state=encoder_states[2:4])\n",
        "decoder_outputs3, _, _ = decoder_lstm3(decoder_outputs2, initial_state=encoder_states[4:6])\n",
        "# decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "# decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs1)\n",
        "\n",
        "#decoder_dense = Dense(latent_dim, activation='sigmoid')\n",
        "#decoder_dense_outputs = decoder_dense(decoder_outputs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDtJiUjbuQ_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "#model = Model([encoder_inputs, decoder_inputs], decoder_dense_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2oVO9SSlumSN",
        "colab_type": "code",
        "outputId": "6ab3f2f0-482c-403a-82c5-aa0683050269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    1000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    1000000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 100),  80400       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 100),  80400       embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 100),  80400       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 100),  80400       lstm_4[0][0]                     \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 100),  80400       lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 100),  80400       lstm_5[0][0]                     \n",
            "                                                                 lstm_3[0][1]                     \n",
            "                                                                 lstm_3[0][2]                     \n",
            "==================================================================================================\n",
            "Total params: 2,482,400\n",
            "Trainable params: 482,400\n",
            "Non-trainable params: 2,000,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jui6e2GhuqAU",
        "colab_type": "code",
        "outputId": "620312f5-4165-4bd3-95cc-0a50ebeb9f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6834
        }
      },
      "cell_type": "code",
      "source": [
        "#from keras import losses\n",
        "# Run training\n",
        "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
        "# rather than sequences of integers like `decoder_input_data`!\n",
        "model.compile(optimizer='adam', loss='cosine_proximity', metrics=['acc'])\n",
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=200,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 30 samples\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: -0.1714 - acc: 0.3138 - val_loss: -0.4172 - val_acc: 0.4926\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.4717 - acc: 0.5263 - val_loss: -0.5054 - val_acc: 0.4596\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5352 - acc: 0.5053 - val_loss: -0.5273 - val_acc: 0.4963\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.5483 - acc: 0.5661 - val_loss: -0.5355 - val_acc: 0.5257\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5539 - acc: 0.5779 - val_loss: -0.5393 - val_acc: 0.5257\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5600 - acc: 0.5808 - val_loss: -0.5406 - val_acc: 0.5257\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5625 - acc: 0.5811 - val_loss: -0.5419 - val_acc: 0.5257\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5638 - acc: 0.5815 - val_loss: -0.5428 - val_acc: 0.5257\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5634 - acc: 0.5811 - val_loss: -0.5437 - val_acc: 0.5257\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5647 - acc: 0.5794 - val_loss: -0.5439 - val_acc: 0.5257\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5662 - acc: 0.5796 - val_loss: -0.5443 - val_acc: 0.5257\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5649 - acc: 0.5752 - val_loss: -0.5447 - val_acc: 0.5257\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5656 - acc: 0.5755 - val_loss: -0.5450 - val_acc: 0.5257\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5701 - acc: 0.5795 - val_loss: -0.5446 - val_acc: 0.5257\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5713 - acc: 0.5782 - val_loss: -0.5443 - val_acc: 0.5257\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5730 - acc: 0.5773 - val_loss: -0.5436 - val_acc: 0.5257\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5744 - acc: 0.5768 - val_loss: -0.5404 - val_acc: 0.5037\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5755 - acc: 0.5588 - val_loss: -0.5400 - val_acc: 0.5257\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5770 - acc: 0.5723 - val_loss: -0.5242 - val_acc: 0.4485\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5812 - acc: 0.5547 - val_loss: -0.5347 - val_acc: 0.5221\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5803 - acc: 0.5704 - val_loss: -0.5104 - val_acc: 0.4191\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5848 - acc: 0.5389 - val_loss: -0.5308 - val_acc: 0.5037\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5813 - acc: 0.5734 - val_loss: -0.5046 - val_acc: 0.4154\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5819 - acc: 0.5063 - val_loss: -0.5285 - val_acc: 0.4743\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.5842 - acc: 0.5722 - val_loss: -0.5380 - val_acc: 0.4926\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5915 - acc: 0.5507 - val_loss: -0.5082 - val_acc: 0.4191\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5936 - acc: 0.5281 - val_loss: -0.5276 - val_acc: 0.4890\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.5951 - acc: 0.5551 - val_loss: -0.4988 - val_acc: 0.4228\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6035 - acc: 0.5253 - val_loss: -0.5002 - val_acc: 0.4485\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6093 - acc: 0.5532 - val_loss: -0.4753 - val_acc: 0.4228\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6126 - acc: 0.5326 - val_loss: -0.4777 - val_acc: 0.4596\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6133 - acc: 0.5488 - val_loss: -0.4531 - val_acc: 0.4118\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6127 - acc: 0.5550 - val_loss: -0.4880 - val_acc: 0.4301\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6201 - acc: 0.5515 - val_loss: -0.4705 - val_acc: 0.4449\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6257 - acc: 0.5614 - val_loss: -0.4626 - val_acc: 0.4412\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6360 - acc: 0.5566 - val_loss: -0.4251 - val_acc: 0.4044\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.6343 - acc: 0.5792 - val_loss: -0.4534 - val_acc: 0.4632\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6424 - acc: 0.5817 - val_loss: -0.4559 - val_acc: 0.4485\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.6497 - acc: 0.5682 - val_loss: -0.4545 - val_acc: 0.4485\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6588 - acc: 0.6082 - val_loss: -0.4515 - val_acc: 0.4338\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6687 - acc: 0.5834 - val_loss: -0.4613 - val_acc: 0.4485\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6788 - acc: 0.6114 - val_loss: -0.4621 - val_acc: 0.4522\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6873 - acc: 0.6321 - val_loss: -0.4419 - val_acc: 0.4449\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6906 - acc: 0.6386 - val_loss: -0.4569 - val_acc: 0.4632\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6916 - acc: 0.6507 - val_loss: -0.4863 - val_acc: 0.4522\n",
            "Epoch 46/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6886 - acc: 0.6375 - val_loss: -0.4776 - val_acc: 0.4743\n",
            "Epoch 47/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.6987 - acc: 0.6592 - val_loss: -0.4763 - val_acc: 0.4669\n",
            "Epoch 48/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7035 - acc: 0.6622 - val_loss: -0.4635 - val_acc: 0.4743\n",
            "Epoch 49/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7078 - acc: 0.6712 - val_loss: -0.4772 - val_acc: 0.4779\n",
            "Epoch 50/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7097 - acc: 0.6722 - val_loss: -0.4620 - val_acc: 0.4669\n",
            "Epoch 51/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7112 - acc: 0.6712 - val_loss: -0.4707 - val_acc: 0.4743\n",
            "Epoch 52/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7146 - acc: 0.6762 - val_loss: -0.4492 - val_acc: 0.4743\n",
            "Epoch 53/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7166 - acc: 0.6821 - val_loss: -0.4755 - val_acc: 0.4890\n",
            "Epoch 54/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7182 - acc: 0.6795 - val_loss: -0.4569 - val_acc: 0.4779\n",
            "Epoch 55/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7205 - acc: 0.6811 - val_loss: -0.4662 - val_acc: 0.4853\n",
            "Epoch 56/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7203 - acc: 0.6741 - val_loss: -0.4446 - val_acc: 0.4669\n",
            "Epoch 57/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7223 - acc: 0.6762 - val_loss: -0.4677 - val_acc: 0.4816\n",
            "Epoch 58/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7234 - acc: 0.6780 - val_loss: -0.4500 - val_acc: 0.4779\n",
            "Epoch 59/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7235 - acc: 0.6772 - val_loss: -0.4563 - val_acc: 0.4816\n",
            "Epoch 60/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7249 - acc: 0.6751 - val_loss: -0.4480 - val_acc: 0.4743\n",
            "Epoch 61/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7262 - acc: 0.6724 - val_loss: -0.4581 - val_acc: 0.4779\n",
            "Epoch 62/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7273 - acc: 0.6765 - val_loss: -0.4451 - val_acc: 0.4706\n",
            "Epoch 63/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7285 - acc: 0.6744 - val_loss: -0.4542 - val_acc: 0.4816\n",
            "Epoch 64/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7281 - acc: 0.6771 - val_loss: -0.4451 - val_acc: 0.4669\n",
            "Epoch 65/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7301 - acc: 0.6704 - val_loss: -0.4428 - val_acc: 0.4779\n",
            "Epoch 66/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7308 - acc: 0.6717 - val_loss: -0.4435 - val_acc: 0.4669\n",
            "Epoch 67/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7327 - acc: 0.6738 - val_loss: -0.4427 - val_acc: 0.4743\n",
            "Epoch 68/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7335 - acc: 0.6663 - val_loss: -0.4433 - val_acc: 0.4743\n",
            "Epoch 69/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7345 - acc: 0.6729 - val_loss: -0.4367 - val_acc: 0.4596\n",
            "Epoch 70/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7360 - acc: 0.6727 - val_loss: -0.4356 - val_acc: 0.4669\n",
            "Epoch 71/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7371 - acc: 0.6769 - val_loss: -0.4335 - val_acc: 0.4596\n",
            "Epoch 72/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7382 - acc: 0.6693 - val_loss: -0.4324 - val_acc: 0.4596\n",
            "Epoch 73/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7384 - acc: 0.6707 - val_loss: -0.4312 - val_acc: 0.4559\n",
            "Epoch 74/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7395 - acc: 0.6710 - val_loss: -0.4277 - val_acc: 0.4559\n",
            "Epoch 75/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7400 - acc: 0.6711 - val_loss: -0.4294 - val_acc: 0.4596\n",
            "Epoch 76/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7417 - acc: 0.6779 - val_loss: -0.4237 - val_acc: 0.4522\n",
            "Epoch 77/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7420 - acc: 0.6701 - val_loss: -0.4278 - val_acc: 0.4559\n",
            "Epoch 78/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7426 - acc: 0.6682 - val_loss: -0.4253 - val_acc: 0.4559\n",
            "Epoch 79/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7432 - acc: 0.6700 - val_loss: -0.4250 - val_acc: 0.4449\n",
            "Epoch 80/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7444 - acc: 0.6731 - val_loss: -0.4270 - val_acc: 0.4412\n",
            "Epoch 81/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7464 - acc: 0.6755 - val_loss: -0.4214 - val_acc: 0.4522\n",
            "Epoch 82/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7457 - acc: 0.6670 - val_loss: -0.4253 - val_acc: 0.4522\n",
            "Epoch 83/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7454 - acc: 0.6724 - val_loss: -0.4271 - val_acc: 0.4449\n",
            "Epoch 84/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7458 - acc: 0.6691 - val_loss: -0.4166 - val_acc: 0.4449\n",
            "Epoch 85/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7470 - acc: 0.6737 - val_loss: -0.4126 - val_acc: 0.4265\n",
            "Epoch 86/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7486 - acc: 0.6631 - val_loss: -0.4253 - val_acc: 0.4412\n",
            "Epoch 87/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7486 - acc: 0.6685 - val_loss: -0.4238 - val_acc: 0.4485\n",
            "Epoch 88/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7507 - acc: 0.6750 - val_loss: -0.4142 - val_acc: 0.4449\n",
            "Epoch 89/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7497 - acc: 0.6683 - val_loss: -0.4294 - val_acc: 0.4485\n",
            "Epoch 90/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7499 - acc: 0.6633 - val_loss: -0.4211 - val_acc: 0.4485\n",
            "Epoch 91/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7523 - acc: 0.6726 - val_loss: -0.3990 - val_acc: 0.4118\n",
            "Epoch 92/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7531 - acc: 0.6660 - val_loss: -0.4286 - val_acc: 0.4485\n",
            "Epoch 93/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7544 - acc: 0.6711 - val_loss: -0.4146 - val_acc: 0.4301\n",
            "Epoch 94/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7550 - acc: 0.6665 - val_loss: -0.4135 - val_acc: 0.4228\n",
            "Epoch 95/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7549 - acc: 0.6626 - val_loss: -0.4154 - val_acc: 0.4375\n",
            "Epoch 96/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7570 - acc: 0.6768 - val_loss: -0.4053 - val_acc: 0.4154\n",
            "Epoch 97/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7574 - acc: 0.6689 - val_loss: -0.4105 - val_acc: 0.4228\n",
            "Epoch 98/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7577 - acc: 0.6688 - val_loss: -0.4150 - val_acc: 0.4338\n",
            "Epoch 99/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7589 - acc: 0.6691 - val_loss: -0.4149 - val_acc: 0.4265\n",
            "Epoch 100/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7585 - acc: 0.6720 - val_loss: -0.4102 - val_acc: 0.4265\n",
            "Epoch 101/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7597 - acc: 0.6683 - val_loss: -0.3960 - val_acc: 0.4081\n",
            "Epoch 102/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7597 - acc: 0.6664 - val_loss: -0.4225 - val_acc: 0.4338\n",
            "Epoch 103/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7614 - acc: 0.6774 - val_loss: -0.3955 - val_acc: 0.4007\n",
            "Epoch 104/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7605 - acc: 0.6716 - val_loss: -0.4113 - val_acc: 0.4154\n",
            "Epoch 105/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7616 - acc: 0.6617 - val_loss: -0.4245 - val_acc: 0.4338\n",
            "Epoch 106/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7629 - acc: 0.6690 - val_loss: -0.3959 - val_acc: 0.4118\n",
            "Epoch 107/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7633 - acc: 0.6603 - val_loss: -0.4295 - val_acc: 0.4301\n",
            "Epoch 108/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7653 - acc: 0.6692 - val_loss: -0.4142 - val_acc: 0.4265\n",
            "Epoch 109/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7652 - acc: 0.6706 - val_loss: -0.4079 - val_acc: 0.4154\n",
            "Epoch 110/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7670 - acc: 0.6673 - val_loss: -0.4233 - val_acc: 0.4228\n",
            "Epoch 111/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7679 - acc: 0.6746 - val_loss: -0.3995 - val_acc: 0.4081\n",
            "Epoch 112/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7693 - acc: 0.6698 - val_loss: -0.4071 - val_acc: 0.4007\n",
            "Epoch 113/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7702 - acc: 0.6598 - val_loss: -0.3901 - val_acc: 0.4191\n",
            "Epoch 114/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7700 - acc: 0.6679 - val_loss: -0.4057 - val_acc: 0.4081\n",
            "Epoch 115/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7699 - acc: 0.6688 - val_loss: -0.4215 - val_acc: 0.4081\n",
            "Epoch 116/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7702 - acc: 0.6651 - val_loss: -0.3973 - val_acc: 0.4007\n",
            "Epoch 117/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7703 - acc: 0.6705 - val_loss: -0.4117 - val_acc: 0.4118\n",
            "Epoch 118/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7722 - acc: 0.6614 - val_loss: -0.3921 - val_acc: 0.4044\n",
            "Epoch 119/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7733 - acc: 0.6676 - val_loss: -0.4162 - val_acc: 0.4154\n",
            "Epoch 120/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7734 - acc: 0.6788 - val_loss: -0.4038 - val_acc: 0.4081\n",
            "Epoch 121/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7751 - acc: 0.6675 - val_loss: -0.3858 - val_acc: 0.3824\n",
            "Epoch 122/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7768 - acc: 0.6594 - val_loss: -0.4028 - val_acc: 0.4118\n",
            "Epoch 123/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7784 - acc: 0.6719 - val_loss: -0.3875 - val_acc: 0.3971\n",
            "Epoch 124/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7797 - acc: 0.6680 - val_loss: -0.3965 - val_acc: 0.3897\n",
            "Epoch 125/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7811 - acc: 0.6615 - val_loss: -0.3993 - val_acc: 0.4081\n",
            "Epoch 126/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7817 - acc: 0.6734 - val_loss: -0.3963 - val_acc: 0.3860\n",
            "Epoch 127/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7825 - acc: 0.6578 - val_loss: -0.3953 - val_acc: 0.3860\n",
            "Epoch 128/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7829 - acc: 0.6643 - val_loss: -0.3898 - val_acc: 0.3860\n",
            "Epoch 129/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7837 - acc: 0.6641 - val_loss: -0.3792 - val_acc: 0.3640\n",
            "Epoch 130/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7829 - acc: 0.6629 - val_loss: -0.3845 - val_acc: 0.3787\n",
            "Epoch 131/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7842 - acc: 0.6562 - val_loss: -0.3938 - val_acc: 0.3971\n",
            "Epoch 132/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7843 - acc: 0.6715 - val_loss: -0.4051 - val_acc: 0.3713\n",
            "Epoch 133/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7849 - acc: 0.6601 - val_loss: -0.4008 - val_acc: 0.4081\n",
            "Epoch 134/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7846 - acc: 0.6637 - val_loss: -0.4153 - val_acc: 0.3750\n",
            "Epoch 135/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7846 - acc: 0.6636 - val_loss: -0.3997 - val_acc: 0.3971\n",
            "Epoch 136/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7843 - acc: 0.6678 - val_loss: -0.3889 - val_acc: 0.3750\n",
            "Epoch 137/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7848 - acc: 0.6524 - val_loss: -0.4033 - val_acc: 0.4007\n",
            "Epoch 138/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7810 - acc: 0.6660 - val_loss: -0.3943 - val_acc: 0.3934\n",
            "Epoch 139/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7788 - acc: 0.6516 - val_loss: -0.4372 - val_acc: 0.4118\n",
            "Epoch 140/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7789 - acc: 0.6474 - val_loss: -0.3913 - val_acc: 0.4118\n",
            "Epoch 141/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7827 - acc: 0.6762 - val_loss: -0.4038 - val_acc: 0.3787\n",
            "Epoch 142/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7846 - acc: 0.6676 - val_loss: -0.3926 - val_acc: 0.3860\n",
            "Epoch 143/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7862 - acc: 0.6616 - val_loss: -0.4038 - val_acc: 0.3860\n",
            "Epoch 144/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7880 - acc: 0.6794 - val_loss: -0.4078 - val_acc: 0.3934\n",
            "Epoch 145/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7894 - acc: 0.6671 - val_loss: -0.4024 - val_acc: 0.3860\n",
            "Epoch 146/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7901 - acc: 0.6722 - val_loss: -0.4039 - val_acc: 0.3971\n",
            "Epoch 147/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7924 - acc: 0.6675 - val_loss: -0.3791 - val_acc: 0.3750\n",
            "Epoch 148/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7928 - acc: 0.6646 - val_loss: -0.3956 - val_acc: 0.3750\n",
            "Epoch 149/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7935 - acc: 0.6574 - val_loss: -0.3850 - val_acc: 0.3934\n",
            "Epoch 150/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7945 - acc: 0.6779 - val_loss: -0.3957 - val_acc: 0.3824\n",
            "Epoch 151/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7957 - acc: 0.6700 - val_loss: -0.3918 - val_acc: 0.3934\n",
            "Epoch 152/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7963 - acc: 0.6766 - val_loss: -0.3802 - val_acc: 0.3676\n",
            "Epoch 153/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7972 - acc: 0.6706 - val_loss: -0.4027 - val_acc: 0.4007\n",
            "Epoch 154/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7976 - acc: 0.6666 - val_loss: -0.3946 - val_acc: 0.3971\n",
            "Epoch 155/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7978 - acc: 0.6810 - val_loss: -0.3921 - val_acc: 0.3603\n",
            "Epoch 156/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7993 - acc: 0.6687 - val_loss: -0.3814 - val_acc: 0.3824\n",
            "Epoch 157/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8001 - acc: 0.6699 - val_loss: -0.3808 - val_acc: 0.3529\n",
            "Epoch 158/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7999 - acc: 0.6773 - val_loss: -0.3912 - val_acc: 0.3713\n",
            "Epoch 159/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8000 - acc: 0.6676 - val_loss: -0.3845 - val_acc: 0.3713\n",
            "Epoch 160/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8002 - acc: 0.6757 - val_loss: -0.3699 - val_acc: 0.3676\n",
            "Epoch 161/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8013 - acc: 0.6706 - val_loss: -0.3943 - val_acc: 0.3603\n",
            "Epoch 162/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8014 - acc: 0.6733 - val_loss: -0.3988 - val_acc: 0.3713\n",
            "Epoch 163/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8007 - acc: 0.6831 - val_loss: -0.3695 - val_acc: 0.3603\n",
            "Epoch 164/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.7992 - acc: 0.6806 - val_loss: -0.3855 - val_acc: 0.3493\n",
            "Epoch 165/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.7992 - acc: 0.6714 - val_loss: -0.3842 - val_acc: 0.3603\n",
            "Epoch 166/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8009 - acc: 0.6781 - val_loss: -0.3954 - val_acc: 0.3787\n",
            "Epoch 167/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8024 - acc: 0.6911 - val_loss: -0.3593 - val_acc: 0.3309\n",
            "Epoch 168/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8031 - acc: 0.6564 - val_loss: -0.3865 - val_acc: 0.3603\n",
            "Epoch 169/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8050 - acc: 0.6881 - val_loss: -0.3863 - val_acc: 0.3640\n",
            "Epoch 170/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8058 - acc: 0.6714 - val_loss: -0.3753 - val_acc: 0.3419\n",
            "Epoch 171/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8061 - acc: 0.6803 - val_loss: -0.3778 - val_acc: 0.3529\n",
            "Epoch 172/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8070 - acc: 0.6813 - val_loss: -0.3776 - val_acc: 0.3529\n",
            "Epoch 173/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8080 - acc: 0.6833 - val_loss: -0.3833 - val_acc: 0.3529\n",
            "Epoch 174/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8089 - acc: 0.6842 - val_loss: -0.3802 - val_acc: 0.3750\n",
            "Epoch 175/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8084 - acc: 0.6755 - val_loss: -0.3892 - val_acc: 0.3529\n",
            "Epoch 176/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8075 - acc: 0.6870 - val_loss: -0.3949 - val_acc: 0.3713\n",
            "Epoch 177/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8062 - acc: 0.6783 - val_loss: -0.3798 - val_acc: 0.3750\n",
            "Epoch 178/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8081 - acc: 0.6715 - val_loss: -0.3844 - val_acc: 0.3529\n",
            "Epoch 179/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8088 - acc: 0.6819 - val_loss: -0.3848 - val_acc: 0.3493\n",
            "Epoch 180/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8106 - acc: 0.6838 - val_loss: -0.3852 - val_acc: 0.3713\n",
            "Epoch 181/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8104 - acc: 0.6955 - val_loss: -0.3680 - val_acc: 0.3419\n",
            "Epoch 182/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8084 - acc: 0.6702 - val_loss: -0.3937 - val_acc: 0.3787\n",
            "Epoch 183/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8085 - acc: 0.6741 - val_loss: -0.4090 - val_acc: 0.3713\n",
            "Epoch 184/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8062 - acc: 0.6724 - val_loss: -0.3841 - val_acc: 0.3603\n",
            "Epoch 185/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8054 - acc: 0.6680 - val_loss: -0.3943 - val_acc: 0.3713\n",
            "Epoch 186/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8093 - acc: 0.6876 - val_loss: -0.4031 - val_acc: 0.3493\n",
            "Epoch 187/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8101 - acc: 0.6881 - val_loss: -0.3713 - val_acc: 0.3456\n",
            "Epoch 188/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8120 - acc: 0.6907 - val_loss: -0.3976 - val_acc: 0.3860\n",
            "Epoch 189/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8129 - acc: 0.7026 - val_loss: -0.3875 - val_acc: 0.3456\n",
            "Epoch 190/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8147 - acc: 0.6765 - val_loss: -0.3896 - val_acc: 0.3529\n",
            "Epoch 191/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8158 - acc: 0.6988 - val_loss: -0.3870 - val_acc: 0.3640\n",
            "Epoch 192/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8170 - acc: 0.6964 - val_loss: -0.3860 - val_acc: 0.3603\n",
            "Epoch 193/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8185 - acc: 0.6949 - val_loss: -0.3913 - val_acc: 0.3529\n",
            "Epoch 194/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8188 - acc: 0.6836 - val_loss: -0.3914 - val_acc: 0.3824\n",
            "Epoch 195/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8198 - acc: 0.7010 - val_loss: -0.3824 - val_acc: 0.3566\n",
            "Epoch 196/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8199 - acc: 0.6939 - val_loss: -0.3900 - val_acc: 0.3713\n",
            "Epoch 197/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8196 - acc: 0.7016 - val_loss: -0.3803 - val_acc: 0.3456\n",
            "Epoch 198/200\n",
            "116/116 [==============================] - 1s 8ms/step - loss: -0.8200 - acc: 0.7025 - val_loss: -0.3773 - val_acc: 0.3493\n",
            "Epoch 199/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8203 - acc: 0.6870 - val_loss: -0.3906 - val_acc: 0.3750\n",
            "Epoch 200/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: -0.8202 - acc: 0.6941 - val_loss: -0.3912 - val_acc: 0.3824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NPNrnKhUvSfz",
        "colab_type": "code",
        "outputId": "a5d64214-392c-48e1-d048-48bec96ac155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "lAEHbqz9gtf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epochs = range(1,201)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzLK7Cj4gxVp",
        "colab_type": "code",
        "outputId": "23321021-450b-41d8-f2a9-24baa27c92a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,loss_values,'bo', label=\"Training Loss\")\n",
        "plt.plot(epochs,val_loss_values,'b',label=\"Validation Loss\")\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+H90owj+GKC4xAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcd27a947f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_55bPFt-g1pR",
        "colab_type": "code",
        "outputId": "95f1f24b-dc61-4860-ab82-f895ce25893c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,acc_values,'bo', label=\"Training Acc\")\n",
        "plt.plot(epochs,val_acc_values,'b',label=\"Validation Acc\")\n",
        "plt.title('Training and Validation Acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYP5iVQAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcd27a32b70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UE6mQfihg7oi",
        "colab_type": "code",
        "outputId": "10454736-5663-4f79-9df9-7474965117c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save('drive/ml_apps/s2s_3L_chat.h5')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_5 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_2/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnfMXL9pLECK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = model.predict([encoder_input_data, decoder_input_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkIfYAvChGEp",
        "colab_type": "code",
        "outputId": "32de7918-7b4d-4c4c-e3ef-39a54092c0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h1 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c1 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h2 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c2 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h3 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c3 = Input(shape=(latent_dim,))\n",
        "\n",
        "decoder_states_inputs1 = [decoder_state_input_h1, decoder_state_input_c1]\n",
        "decoder_states_inputs2 = [decoder_state_input_h2, decoder_state_input_c2]\n",
        "decoder_states_inputs3 = [decoder_state_input_h3, decoder_state_input_c3]\n",
        "#decoder_states_inputs = [decoder_states_inputs1,decoder_states_inputs2, decoder_states_inputs3 ]\n",
        "decoder_states_inputs = [decoder_state_input_h1, decoder_state_input_c1,decoder_state_input_h2, decoder_state_input_c2,decoder_state_input_h3, decoder_state_input_c3]\n",
        "\n",
        "dex_out = decoder_embedding(decoder_inputs)\n",
        "\n",
        "decoder_outputs1, dstate_h1, dstate_c1 = decoder_lstm1(dex_out, initial_state=decoder_states_inputs[0:2])\n",
        "decoder_outputs2, dstate_h2, dstate_c2 = decoder_lstm2(decoder_outputs1, initial_state=decoder_states_inputs[2:4])\n",
        "decoder_outputs3, dstate_h3, dstate_c3 = decoder_lstm3(decoder_outputs2, initial_state=decoder_states_inputs[4:6])\n",
        "\n",
        "decoder_states1 = [dstate_h1, dstate_c1]\n",
        "decoder_states2 = [dstate_h2, dstate_c2]\n",
        "decoder_states3 = [dstate_h1, dstate_c1]\n",
        "\n",
        "decoder_states = [dstate_h1, dstate_c1, dstate_h2, dstate_c2, dstate_h3, dstate_c3]\n",
        "# decoder_outputs2, dstate_h2, dstate_c2 = decoder_lstm2(decoder_outputs)\n",
        "# decoder_states2 = [dstate_h2, dstate_c2]\n",
        "#decoder_dense_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs3] + decoder_states)\n",
        "#    [decoder_dense_outputs] + decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    1000000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 100),  80400       embedding_2[3][0]                \n",
            "                                                                 input_15[0][0]                   \n",
            "                                                                 input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 100),  80400       lstm_4[3][0]                     \n",
            "                                                                 input_17[0][0]                   \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_19 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 100),  80400       lstm_5[3][0]                     \n",
            "                                                                 input_19[0][0]                   \n",
            "                                                                 input_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,241,200\n",
            "Trainable params: 241,200\n",
            "Non-trainable params: 1,000,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NiOh14MbpFD6",
        "colab_type": "code",
        "outputId": "c96646ed-1490-4fc6-b416-62cb056f5c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_model.save('drive/ml_apps/chat_encoder_3L_model.h5')\n",
        "decoder_model.save('drive/ml_apps/chat_decoder_3L_model.h5')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_15:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'input_16:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_5 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_17:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'input_18:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_19:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'input_20:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Chz7QjsdhT7Y",
        "colab_type": "code",
        "outputId": "336671da-853f-4d91-f080-35f1a19212df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, None, 100), (None 80400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                [(None, None, 100), (None 80400     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                [(None, None, 100), (None 80400     \n",
            "=================================================================\n",
            "Total params: 1,241,200\n",
            "Trainable params: 241,200\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EtGT5zUqhgAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Reverse-lookup token index to decode sequences back to\n",
        "# # something readable.\n",
        "# reverse_input_word_index = dict(\n",
        "#     (i, word) for word, i in input_token_index.items())\n",
        "# reverse_target_word_index = dict(\n",
        "#     (i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eok0QQuIs_QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_seq(val_seq):\n",
        "  x_val_sent=[]\n",
        "  for i in range(len(val_seq)):\n",
        "    x_val_sent.append(reverse_word_index[val_seq[i]]) \n",
        "  return x_val_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8NdcRgYyIvA",
        "colab_type": "code",
        "outputId": "16ae146f-4b34-4a91-948b-acf527d1428e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "word_seq(encoder_input_data[9])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '.',\n",
              " 'good',\n",
              " 'is',\n",
              " 'that']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "AayRZXqshhGW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    \n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    #print(\"states_value:\", states_value)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    \n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    \n",
        "    #target_seq[0, 0] = target_token_index['bol']\n",
        "    target_seq[0, 0] = vocab_token_index['bol']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    token_index = []\n",
        "    #t = 1\n",
        "    while not stop_condition:\n",
        "    #for t in range(0,max_decoder_seq_length):\n",
        "        \n",
        "        output_tokens,h1,c1,h2,c2,h3,c3 = decoder_model.predict(\n",
        "             [target_seq] + states_value)\n",
        "        \n",
        "        # Sample a token\n",
        "        #print(\"shape output_tokens:\", output_tokens.shape)\n",
        "        #sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        output_word_embedding = np.reshape(output_tokens[0,-1,:],(1,latent_dim))\n",
        "        sampled_similar = cosine_similarity(output_word_embedding,embedding_matrix)\n",
        "        #print(\"Sampled similar:\", sampled_similar.shape)\n",
        "        sampled_token_index = np.argmax(sampled_similar)\n",
        "                                           \n",
        "        #sampled_word = reverse_target_word_index[sampled_token_index]\n",
        "        sampled_word = reverse_word_index[sampled_token_index]\n",
        "        \n",
        "      \n",
        "\n",
        "        if (sampled_word != 'eol'):\n",
        "          decoded_sentence += sampled_word + ' '\n",
        "          token_index.append(sampled_token_index)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_word == 'eol' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        \n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h1, c1, h2,c2, h3,c3]\n",
        "        \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilmKDwh9iSP7",
        "colab_type": "code",
        "outputId": "7f1bafce-0e05-4be3-9b25-80507c735498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "for seq_index in range(11,21):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index+1]\n",
        "    \n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: See you later.\n",
            "Decoded sentence: bye . \n",
            "-\n",
            "Input sentence: Hello\n",
            "Decoded sentence: hi \n",
            "-\n",
            "Input sentence: Hi\n",
            "Decoded sentence: how are you doing ? \n",
            "-\n",
            "Input sentence: How are you doing?\n",
            "Decoded sentence: i am doing well . \n",
            "-\n",
            "Input sentence: I am doing well.\n",
            "Decoded sentence: that is good to hear \n",
            "-\n",
            "Input sentence: That is good to hear\n",
            "Decoded sentence: yes it is . \n",
            "-\n",
            "Input sentence: Yes it is.\n",
            "Decoded sentence: know not so well you you \n",
            "-\n",
            "Input sentence: Can I help you with anything?\n",
            "Decoded sentence: yes . happy has one question . \n",
            "-\n",
            "Input sentence: Yes, I have a question.\n",
            "Decoded sentence: what is your question ? \n",
            "-\n",
            "Input sentence: What is your question?\n",
            "Decoded sentence: could you borrow the cup is sugar ? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aJH1v5TCiel6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_text(input_text):\n",
        "  tokens_in=[]\n",
        "  input_data = np.zeros(\n",
        "    (1,max_encoder_seq_length),\n",
        "    dtype='float32')\n",
        "  tokens_in = nltk.word_tokenize(input_text.lower())\n",
        "  for i in range(len(tokens_in)):\n",
        "    #print(tokens_in[i])\n",
        "    if tokens_in[i] in input_words:\n",
        "     \n",
        "      input_data[0,i] = vocab_token_index[tokens_in[i]]\n",
        "    else:\n",
        "      input_data[0,i] = vocab_token_index['.']\n",
        "  input_data = np.fliplr(input_data)\n",
        "  return input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yp09Q84Nz_Dq",
        "colab_type": "code",
        "outputId": "5c669d1c-9036-40b7-b5aa-ac6e4640853c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "data = prepare_text(\"Hello\")\n",
        "print(data[0,], data.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0. 127.] (1, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FFoIsrfa0HGh",
        "colab_type": "code",
        "outputId": "2385f16a-fd02-48d2-d18f-1c9a74bfbc7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "new_sentence = decode_sequence(data)\n",
        "print('-')\n",
        "#print('Input sentence:', )\n",
        "print('Decoded sentence:', new_sentence)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Decoded sentence: hi \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_pXra59MTaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        },
        "outputId": "4d17bb59-afd6-4a1c-d3b0-bb2633aca401"
      },
      "cell_type": "code",
      "source": [
        "end_session = False\n",
        "of = open('drive/ml_apps/user_input2.txt','a')\n",
        "while not end_session:\n",
        "    x = input(\"Enter >>\");\n",
        "    #print(\">>\", x)\n",
        "    if x.lower() == \"bye\":\n",
        "      print(\">>\", x)\n",
        "      end_session = False\n",
        "      of.close()\n",
        "      break\n",
        "    in_text = prepare_text(x)\n",
        "    prediction =decode_sequence(in_text)\n",
        "    print (\"Response >>\",prediction)\n",
        "    fdbk = input(\"Is this response satisfactory? (Y/N)>>\")\n",
        "    if fdbk == \"N\":\n",
        "      gd_response = input(\"Please enter expected response>>\")\n",
        "      output = x + ' \\t ' + gd_response + '\\n'\n",
        "      of.write(output)\n",
        "\n",
        "      \n",
        "    "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter >>Hello\n",
            "Response >> hi \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>How are you doing?\n",
            "Response >> i am doing well . \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>Can you help me?\n",
            "Response >> know so now you is ? \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>I can try.\n",
            "Enter >>I want to learn a language.\n",
            "Response >> have you not if only do . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>What language?\n",
            "Enter >>Some programming language.\n",
            "Response >> bye what . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>Like python.\n",
            "Enter >>Do you know python?\n",
            "Response >> i 'm are better . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>A little\n",
            "Enter >>What about Java?\n",
            "Response >> i what is to myself . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>Not much really. \n",
            "Enter >>Do you like movies?\n",
            "Response >> what of kind you ? \n",
            "Is this response satisfactory? (Y/N)>>Of what kind?\n",
            "Enter >>Horror movies?\n",
            "Response >> know you my of use ? \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>I do not like horror movies?\n",
            "Enter >>Do you like comedies?\n",
            "Response >> that is good to tell \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>What do you like?\n",
            "Enter >>What do you like?\n",
            "Response >> what is way you \n",
            "Is this response satisfactory? (Y/N)>>What do you want me to like?\n",
            "Enter >>You tell me.\n",
            "Response >> i you not . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>I will not. \n",
            "Enter >>Why?\n",
            "Response >> i \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>Because\n",
            "Enter >>I am baking a cake.\n",
            "Response >> what what is a cake ? \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>A cake is a food.\n",
            "Response >> what is you . \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>I am a human being.\n",
            "Response >> that is you do to why . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>Good to know. \n",
            "Enter >>I like to eat cake.\n",
            "Response >> what is you those you like so ? \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>I don't like cakes.\n",
            "Enter >>Why not?\n",
            "Response >> i am not authorized . \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>I understand.\n",
            "Response >> you you did the what are if . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>Thanks for understanding.\n",
            "Enter >>What can you do?\n",
            "Response >> i i complicated . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>It is complicated.\n",
            "Enter >>What is life?\n",
            "Response >> you not so is him . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>That is a difficult question.\n",
            "Enter >>What is your favorite book?\n",
            "Response >> i know not not . \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>what is your favorite color?\n",
            "Response >> blue \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>Why not red?\n",
            "Response >> that is an absurd question . \n",
            "Is this response satisfactory? (Y/N)>>I don't think so\n",
            "Enter >>I don't think so\n",
            "Response >> i know do not not this you . \n",
            "Is this response satisfactory? (Y/N)>>N\n",
            "Please enter expected response>>That's your choice.\n",
            "Enter >>What kind of movies do you like?\n",
            "Response >> alice in wonderland \n",
            "Is this response satisfactory? (Y/N)>>Y\n",
            "Enter >>I like it too. \n",
            "Response >> what not you not not not way to do \n",
            "Is this response satisfactory? (Y/N)>>bye\n",
            "Enter >>bye\n",
            ">> bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tO_DqA18QlyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}